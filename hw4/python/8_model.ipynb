{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "e1cDMWdOjJ2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook (and the slides from lecture 8) will help you go straight from training a model in Colab to deploying it in a webpage with TensorFlow.js - without having to leave the browser."
      ]
    },
    {
      "metadata": {
        "id": "248xIjNGCRU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Configure this notebook to work with your GitHub account by populating these fields."
      ]
    },
    {
      "metadata": {
        "id": "Ft9uEY7UCH46",
        "colab_type": "code",
        "outputId": "851462e3-8758-42df-9465-0772b89a723d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.6/dist-packages (0.6.7)\n",
            "Requirement already satisfied: keras==2.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.2)\n",
            "Requirement already satisfied: tensorflow-hub==0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.1)\n",
            "Requirement already satisfied: numpy==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.1)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: tensorflow==1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing==1.0.2 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: keras-applications==1.0.4 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.0.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.1.1->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.32.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.1.1->tensorflowjs) (40.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gTIUM0F4RV-a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import urllib\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g4k9_Ke9CaOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# your github username\n",
        "USER_NAME = \"fak2116\" \n",
        "\n",
        "# the email associated with your commits\n",
        "# (may not matter if you leave it as this)\n",
        "USER_EMAIL = \"fak2116@columbia.edu\" \n",
        "\n",
        "# the user token you've created (see the lecture 8 slides for instructions)\n",
        "TOKEN = \"17dc2583939cda3c3ce680de2ef733596a40666e\" \n",
        "\n",
        "# site name\n",
        "# for example, if my user_name is \"foo\", then this notebook will create\n",
        "# a site at https://foo.github.io/hw4/\n",
        "SITE_NAME = \"hw4\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnPqmO8vDDwW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, run this cell to configure git."
      ]
    },
    {
      "metadata": {
        "id": "Q0IMoqVdCIb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git config --global user.email {USER_NAME}\n",
        "!git config --global user.name  {USER_EMAIL}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XYfDxuMfDVas",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clone your GitHub pages repo (see the lecture 8 slides for instructions on how to create one)."
      ]
    },
    {
      "metadata": {
        "id": "qRUyZiFqDUxt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "repo_path = USER_NAME + '.github.io'\n",
        "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
        "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qu4OA27iDU0e",
        "colab_type": "code",
        "outputId": "513e8051-e70e-4c12-8150-02cfd4567747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "cell_type": "code",
      "source": [
        "os.chdir(repo_path)\n",
        "!git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/fak2116/fak2116.github.io\n",
            "   69c6942..1f2ed50  master     -> origin/master\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KgISB_cAHPIs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a folder for your site."
      ]
    },
    {
      "metadata": {
        "id": "UAA6t4slF0nB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
        "if not os.path.exists(project_path): \n",
        "  os.mkdir(project_path)\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwYh8sXKHs3O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These paths will be used by the converter script."
      ]
    },
    {
      "metadata": {
        "id": "ABggwdWMGe2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY\n",
        "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJpu2BkSUWe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As an example, we will create and vectorize a few documents. (Check out https://www.gutenberg.org/ for a bunch of free e-books.)"
      ]
    },
    {
      "metadata": {
        "id": "PgQUquaMzXq3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "urls = [\"https://www.gutenberg.org/files/58344/58344-0.txt\", \"https://www.gutenberg.org/files/11/11-0.txt\", \"https://www.gutenberg.org/files/98/98-0.txt\"]\n",
        "beginning = [\"In the shade\", \"Alice was beginning\", \"It was the best\"]\n",
        "dest = \"temp\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dTOE-q2hVSgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "244f2130-d19a-4c3d-e504-077522cedf86"
      },
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "texts = []\n",
        "test = []\n",
        "\n",
        "for i, url, begintext in zip(range(3), urls, beginning): \n",
        "  urllib.request.urlretrieve(url, dest)\n",
        "  text = open(dest).read().lower()\n",
        "  print('Corpus length:', len(text))\n",
        "  f = open(dest)\n",
        "  text = f.read()\n",
        "  beginindex = text.find(begintext)\n",
        "  sentences = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', text[beginindex:])\n",
        "  sentences = [s.replace(\"\\n\", ' ') for s in sentences]\n",
        "  subset = sentences[:1000]\n",
        "  texts += subset\n",
        "  labels += [i]*1000\n",
        "  test += sentences[1000:1002]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus length: 255017\n",
            "Corpus length: 163817\n",
            "Corpus length: 776697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ppTtVSPbcRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "46130a3c-0cc2-4276-dcaa-142843ac05cb"
      },
      "cell_type": "code",
      "source": [
        "print (len(labels))\n",
        "print (texts[999])\n",
        "print (test[0])\n",
        "print (len(test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n",
            " Worthless, it seemed to him, worthless and meaningless was the life he had been leading; nothing living, nothing that was in anyway beautiful or worth keeping had remained with him\n",
            "He stood there alone and empty, like a castaway on the shore\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kFy4zWSohPDm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=texts\n",
        "y_train=labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0TpZN19l_6rI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Shuffle the training examples\n",
        "\n",
        "npx = np.array(x_train)\n",
        "npy = np.array(y_train)\n",
        "np.random.seed(0)\n",
        "indices = np.arange(len(x_train))\n",
        "np.random.shuffle(indices)\n",
        "npx = npx[indices]\n",
        "npy = npy[indices]\n",
        "x_train = npx.tolist()\n",
        "y_train = npy.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3cLm-EV344Om",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store back in texts and labels\n",
        "texts = x_train\n",
        "labels = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVfStwZCYBAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenize the documents, create a word index (word -> number)."
      ]
    },
    {
      "metadata": {
        "id": "HOHTxREVQalF",
        "colab_type": "code",
        "outputId": "31e0a0ca-c0fa-43c2-b0e5-3ea0744a31a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "num_words = 1000\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# Fit the tokenizer on the training data\n",
        "t = Tokenizer(num_words=num_words)\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "mqyqHuLwWT-Z",
        "colab_type": "code",
        "outputId": "745c2f69-9bfb-428e-c639-6f778a1a3e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "#print(t.word_index)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "feIAyrrxYFoU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's how we vectorize a document."
      ]
    },
    {
      "metadata": {
        "id": "Jfi7tJbHTwIc",
        "colab_type": "code",
        "outputId": "5cb39b0c-daa0-4095-be71-3e14dc8c9c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "vectorized = t.texts_to_sequences([texts[0]])\n",
        "print(vectorized)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[36, 265, 396, 24, 242, 859, 1, 587, 95, 8, 49, 2, 1, 103, 195, 215, 22, 35, 1, 4, 10, 356, 1, 4, 10, 95, 37, 37, 860, 37, 37, 74, 29, 199, 86, 216, 2, 356]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vUfL6MVhYHof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apply padding if necessary."
      ]
    },
    {
      "metadata": {
        "id": "rbghRbY5QaMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xwd6ND_UIKk",
        "colab_type": "code",
        "outputId": "f5b3bc41-b6b2-4837-9c3c-a443ba91976b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(padded)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1   4  10 356   1   4  10  95  37  37 860  37  37  74  29 199  86 216\n",
            "    2 356]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C9NUXTTuYLZ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will save the word index in metadata. Later, we'll use it to convert words typed in the browser to numbers for prediction."
      ]
    },
    {
      "metadata": {
        "id": "UpzusXHhULBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata = {\n",
        "  'word_index': t.word_index,\n",
        "  'max_len': max_len,\n",
        "  'vocabulary_size': num_words,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6VOtCRJiYWZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare some training data."
      ]
    },
    {
      "metadata": {
        "id": "-Q8Y1ZuZYYKC",
        "colab_type": "code",
        "outputId": "fdfc37f1-d966-4754-a5f1-940f66da1d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = t.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
        "print(x_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1   4  10 ... 216   2 356]\n",
            " [ 90 861 777 ...   0   0   0]\n",
            " [  7  13  21 ...  12  93 112]\n",
            " ...\n",
            " [314 233  77 ...   0   0   0]\n",
            " [192  17  21 ...   0   0   0]\n",
            " [ 17 182  63 ...   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l57eA3ApZGsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a model."
      ]
    },
    {
      "metadata": {
        "id": "oLQeTh3uVqtj",
        "colab_type": "code",
        "outputId": "80760f36-29f1-4b68-a333-8c903e7876f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 64\n",
        "n_classes = 3\n",
        "epochs = 5\n",
        "\n",
        "import keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "#model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.LSTM(128, return_sequences=True))\n",
        "#model.add(keras.layers.LSTM(128, return_sequences=True))\n",
        "#model.add(keras.layers.LSTM(128, return_sequences=True))\n",
        "model.add(keras.layers.LSTM(128))\n",
        "#model.add(keras.layers.Dense(256, activation='relu'))\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 64)            64000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 20, 128)           98816     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 294,787\n",
            "Trainable params: 294,787\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VUWlD3jiX10c",
        "colab_type": "code",
        "outputId": "7a951203-9d20-4312-f5e7-509ca5e92395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=epochs, validation_split=.1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2700 samples, validate on 300 samples\n",
            "Epoch 1/5\n",
            "2700/2700 [==============================] - 8s 3ms/step - loss: 0.8653 - acc: 0.5552 - val_loss: 0.5913 - val_acc: 0.7300\n",
            "Epoch 2/5\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.4601 - acc: 0.8078 - val_loss: 0.4027 - val_acc: 0.8367\n",
            "Epoch 3/5\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.3036 - acc: 0.8926 - val_loss: 0.4660 - val_acc: 0.8100\n",
            "Epoch 4/5\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.2221 - acc: 0.9204 - val_loss: 0.4034 - val_acc: 0.8400\n",
            "Epoch 5/5\n",
            "2700/2700 [==============================] - 6s 2ms/step - loss: 0.1693 - acc: 0.9404 - val_loss: 0.4924 - val_acc: 0.8500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd741c08ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "y1YbPNWIenE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Demo using the model to make predictions."
      ]
    },
    {
      "metadata": {
        "id": "C5EQktUMI5Y2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "217789df-9093-4b93-a4b1-def320f3ab71"
      },
      "cell_type": "code",
      "source": [
        "test_example = \"As Siddhartha left the grove where the buddha, the perfect one, remained behind, where Govinda remained behind, he felt that he was also leaving behind his life so far, that it was separating itself from him.\"\n",
        "x_test = t.texts_to_sequences([test_example])\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
        "print(x_test)\n",
        "preds = model.predict(x_test)\n",
        "print(preds)\n",
        "import numpy as np\n",
        "print(np.argmax(preds))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[250 255   8 154  11   8   9 519 864 255  10 136  36 336  11   7   9 292\n",
            "   35  22]]\n",
            "[[9.9995959e-01 1.3686732e-05 2.6658401e-05]]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ye7z9VdoI-fR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test the model on the collected test sentences"
      ]
    },
    {
      "metadata": {
        "id": "KcmpKvKUY_hK",
        "colab_type": "code",
        "outputId": "c7215019-318a-4546-aa20-6bcdb12c6995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "cell_type": "code",
      "source": [
        "for ex in test:\n",
        "  print (ex)\n",
        "  test_example = ex\n",
        "  x_test = t.texts_to_sequences([test_example])\n",
        "  x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
        "  print(x_test)\n",
        "  preds = model.predict(x_test)\n",
        "  print(preds)\n",
        "  import numpy as np\n",
        "  print(np.argmax(preds))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He stood there alone and empty, like a castaway on the shore\n",
            "[[  8 209  41 305   2 855  53   5  24   1   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "[[0.8461247  0.03898405 0.11489121]]\n",
            "0\n",
            "  In low spirits, Siddhartha betook himself to one of the pleasure gardens he owned, he locked the gate, sat down under a mango tree, felt the death in his heart and bleakness in his heart, he sat and felt how something in him was dying, wilting, coming to its end\n",
            "[[  6  10 188   2   6  10 188   8 217   2 154  90 127   6  22   9 547   3\n",
            "   70 277]]\n",
            "[[0.9939143  0.00149519 0.00459053]]\n",
            "0\n",
            "’  The soldiers were silent, and looked at Alice, as the question was evidently meant for her\n",
            "[[ 13   1 981  39 323   2  83  23  34  18   1 301   9  20  26   0   0   0\n",
            "    0   0]]\n",
            "[[7.0537822e-06 9.9996901e-01 2.3927287e-05]]\n",
            "1\n",
            "  ‘Yes\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "[[0.09965076 0.5978687  0.30248055]]\n",
            "1\n",
            "Your bank-notes had a musty odour, as if they were fast decomposing into rags again\n",
            "[[ 73 317  15   5  18  50  38  39 644  51  71   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "[[0.02480188 0.0212717  0.95392644]]\n",
            "2\n",
            "Your plate was stowed away among the neighbouring cesspools, and evil communications corrupted its good polish in a day or two\n",
            "[[ 73   9 163 172   1   2  70 102   6   5 109  55 103   0   0   0   0   0\n",
            "    0   0]]\n",
            "[[0.09935348 0.12738952 0.7732571 ]]\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G-Kuwvqcfptq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert the model"
      ]
    },
    {
      "metadata": {
        "id": "nyo2Q_ehe2RT",
        "colab_type": "code",
        "outputId": "5a9f45b9-aa18-41c7-922f-a810871c59a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
        "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
        "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
        "print('\\nSaved model artifacts in directory: %s' % MODEL_DIR)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model artifacts in directory: /content/fak2116.github.io/hw4/model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z609mw1aj-RJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Write an index.html and an index.js file configured to load our model."
      ]
    },
    {
      "metadata": {
        "id": "IoFAxt8nj9fp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "index_html = \"\"\"\n",
        "<!doctype html>\n",
        "\n",
        "<body>\n",
        "  <style>\n",
        "    #textfield {\n",
        "      font-size: 120%;\n",
        "      width: 60%;\n",
        "      height: 200px;\n",
        "    }\n",
        "  </style>\n",
        "  <h1>\n",
        "    HW 4 - Classification \n",
        "  </h1>\n",
        "  <hr>\n",
        "  <div class=\"create-model\">\n",
        "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
        "  </div>\n",
        "  <div>\n",
        "    <div>\n",
        "      <span>Vocabulary size: </span>\n",
        "      <span id=\"vocabularySize\"></span>\n",
        "    </div>\n",
        "    <div>\n",
        "      <span>Max length: </span>\n",
        "      <span id=\"maxLen\"></span>\n",
        "    </div>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <select id=\"example-select\" class=\"form-control\">\n",
        "      <option value=\"example1\">SIDDHARTHA: A poem of India</option>\n",
        "      <option value=\"example2\">Alice's Adventures in Wonderland</option>\n",
        "      <option value=\"example3\">A Tale of Two Cities</option>\n",
        "    </select>\n",
        "  </div>\n",
        "  <div>\n",
        "    <textarea id=\"text-entry\"></textarea>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <span id=\"status\">Standing by.</span>\n",
        "  </div>\n",
        "\n",
        "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
        "  <script src='index.js'></script>\n",
        "</body>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JsQLbLnkhhk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_js = \"\"\"\n",
        "const HOSTED_URLS = {\n",
        "  model:\n",
        "      'model_js/model.json',\n",
        "  metadata:\n",
        "      'model_js/metadata.json'\n",
        "};\n",
        "\n",
        "const examples = {\n",
        "  'example1':\n",
        "      'He stood there alone and empty, like a castaway on the shore',\n",
        "  'example2':\n",
        "      'Alice was beginning to get very tired of sitting by her sister on the bank',\n",
        "  'example3':\n",
        "      'There were a king with a large jaw and a queen with a plain face'      \n",
        "};\n",
        "\n",
        "function status(statusText) {\n",
        "  console.log(statusText);\n",
        "  document.getElementById('status').textContent = statusText;\n",
        "}\n",
        "\n",
        "function showMetadata(metadataJSON) {\n",
        "  document.getElementById('vocabularySize').textContent =\n",
        "      metadataJSON['vocabulary_size'];\n",
        "  document.getElementById('maxLen').textContent =\n",
        "      metadataJSON['max_len'];\n",
        "}\n",
        "\n",
        "function settextField(text, predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.value = text;\n",
        "  doPredict(predict);\n",
        "}\n",
        "\n",
        "function setPredictFunction(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.addEventListener('input', () => doPredict(predict));\n",
        "}\n",
        "\n",
        "function disableLoadModelButtons() {\n",
        "  document.getElementById('load-model').style.display = 'none';\n",
        "}\n",
        "\n",
        "function doPredict(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  const result = predict(textField.value);\n",
        "  score_string = \"Class scores: \";\n",
        "  for (var x in result.score) {\n",
        "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
        "  }\n",
        "  var maxlabel = Object.keys(result).reduce((a, b) => result[a] > result[b] ? a : b);\n",
        "  console.log(\"MaxLabel:\");\n",
        "  console.log(maxlabel);\n",
        "  //console.log(score_string);\n",
        "  status(\n",
        "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
        "}\n",
        "\n",
        "function prepUI(predict) {\n",
        "  setPredictFunction(predict);\n",
        "  const testExampleSelect = document.getElementById('example-select');\n",
        "  testExampleSelect.addEventListener('change', () => {\n",
        "    settextField(examples[testExampleSelect.value], predict);\n",
        "  });\n",
        "  settextField(examples['example1'], predict);\n",
        "}\n",
        "\n",
        "async function urlExists(url) {\n",
        "  status('Testing url ' + url);\n",
        "  try {\n",
        "    const response = await fetch(url, {method: 'HEAD'});\n",
        "    return response.ok;\n",
        "  } catch (err) {\n",
        "    return false;\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedPretrainedModel(url) {\n",
        "  status('Loading pretrained model from ' + url);\n",
        "  try {\n",
        "    const model = await tf.loadModel(url);\n",
        "    status('Done loading pretrained model.');\n",
        "    disableLoadModelButtons();\n",
        "    return model;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading pretrained model failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedMetadata(url) {\n",
        "  status('Loading metadata from ' + url);\n",
        "  try {\n",
        "    const metadataJson = await fetch(url);\n",
        "    const metadata = await metadataJson.json();\n",
        "    status('Done loading metadata.');\n",
        "    return metadata;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading metadata failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "class Classifier {\n",
        "\n",
        "  async init(urls) {\n",
        "    this.urls = urls;\n",
        "    this.model = await loadHostedPretrainedModel(urls.model);\n",
        "    await this.loadMetadata();\n",
        "    return this;\n",
        "  }\n",
        "\n",
        "  async loadMetadata() {\n",
        "    const metadata =\n",
        "        await loadHostedMetadata(this.urls.metadata);\n",
        "    showMetadata(metadata);\n",
        "    this.maxLen = metadata['max_len'];\n",
        "    console.log('maxLen = ' + this.maxLen);\n",
        "    this.wordIndex = metadata['word_index']\n",
        "  }\n",
        "\n",
        "  predict(text) {\n",
        "    // Convert to lower case and remove all punctuations.\n",
        "    const inputText =\n",
        "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
        "    // Look up word indices.\n",
        "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
        "    for (let i = 0; i < inputText.length; ++i) {\n",
        "      const word = inputText[i];\n",
        "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
        "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
        "    }\n",
        "    const input = inputBuffer.toTensor();\n",
        "    //console.log(input);\n",
        "\n",
        "    status('Running inference');\n",
        "    const beginMs = performance.now();\n",
        "    const predictOut = this.model.predict(input);\n",
        "    //console.log(predictOut.dataSync());\n",
        "    const score = predictOut.dataSync();//[0];\n",
        "    predictOut.dispose();\n",
        "    const endMs = performance.now();\n",
        "\n",
        "    return {score: score, elapsed: (endMs - beginMs)};\n",
        "  }\n",
        "};\n",
        "\n",
        "async function setup() {\n",
        "  if (await urlExists(HOSTED_URLS.model)) {\n",
        "    status('Model available: ' + HOSTED_URLS.model);\n",
        "    const button = document.getElementById('load-model');\n",
        "    button.addEventListener('click', async () => {\n",
        "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
        "      prepUI(x => predictor.predict(x));\n",
        "    });\n",
        "    button.style.display = 'inline-block';\n",
        "  }\n",
        "\n",
        "  status('Standing by.');\n",
        "}\n",
        "\n",
        "setup();\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbvVVh1rkmga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('index.html','w') as f:\n",
        "  f.write(index_html)\n",
        "  \n",
        "with open('index.js','w') as f:\n",
        "  f.write(index_js)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0YtvaoazkuRT",
        "colab_type": "code",
        "outputId": "87d7c803-22fa-4f10-f0ee-3d547b7d4321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index.html  index.js  model_js\ttemp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z3NX9FVLiBO7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Commit and push everything. Note: we're storing large binary files in GitHub, this isn't ideal (if you want to deploy a model down the road, better to host it in a cloud storage bucket)."
      ]
    },
    {
      "metadata": {
        "id": "OGkrh5Mhf8wJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pythondir = os.path.join(project_path, \"python\")\n",
        "if not os.path.exists(pythondir):\n",
        "  os.mkdir(pythondir)\n",
        "os.chdir(pythondir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-lD1jAGDhhbb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!touch 8_model.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RoL5aoRUh5DB",
        "colab_type": "code",
        "outputId": "15960f8c-574a-4da7-edcd-099dadca4c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "!git add . \n",
        "!git commit -m \"colab -> github\"\n",
        "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io/ master"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 80fc4cc] colab -> github\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 hw4/python/8_model.ipynb\n",
            "Counting objects: 5, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (5/5), 394 bytes | 394.00 KiB/s, done.\n",
            "Total 5 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/fak2116/fak2116.github.io/\n",
            "   b9948dd..80fc4cc  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WDoo_fDVic2E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All done! Hopefully everything worked. You may need to wait a few moments for the changes to appear in your site. If not working, check the JavaScript console for errors (in Chrome: View -> Developer -> JavaScript Console)."
      ]
    },
    {
      "metadata": {
        "id": "1V1QLCxlikOI",
        "colab_type": "code",
        "outputId": "8d9051ac-51dc-4475-de63-d54ad48a7bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Now, visit https://%s.github.io/%s/\" % (USER_NAME, SITE_NAME))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now, visit https://fak2116.github.io/hw4/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mnN6zAHWqPnR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you are debugging and Chrome is failing to pick up your changes, though you've verified they're present in your GitHub repo, see the second answer to: https://superuser.com/questions/89809/how-to-force-refresh-without-cache-in-google-chrome"
      ]
    },
    {
      "metadata": {
        "id": "sBqQPhIIkFhV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
